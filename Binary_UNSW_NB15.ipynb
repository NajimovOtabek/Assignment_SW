{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPsySVoAE6jzCqWnIheSLq5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NajimovOtabek/Assignment_SW/blob/main/Binary_UNSW_NB15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK0R3zS5URB-",
        "outputId": "955be58f-fed0-4911-d3f1-1018f36a83f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AaFPfmUsKhplxHukzQ0k7DKZgEUiDV4A\n",
            "To: /content/UNSW_NB15_training-set.csv\n",
            "100% 15.4M/15.4M [00:00<00:00, 82.5MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IlPVdYv0gGZFJxNclcbUf46vHrWhLWeS\n",
            "To: /content/UNSW_NB15_testing-set.csv\n",
            "100% 32.3M/32.3M [00:00<00:00, 38.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1AaFPfmUsKhplxHukzQ0k7DKZgEUiDV4A\n",
        "!gdown --id 1IlPVdYv0gGZFJxNclcbUf46vHrWhLWeS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Jumabek/net_intrusion_detection/develop/preprocessing.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUPx_l42U1Xa",
        "outputId": "7c6ab871-dbb2-42d3-8e90-1463dc07c173"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-06 10:42:24--  https://raw.githubusercontent.com/Jumabek/net_intrusion_detection/develop/preprocessing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3790 (3.7K) [text/plain]\n",
            "Saving to: ‘preprocessing.py’\n",
            "\n",
            "\rpreprocessing.py      0%[                    ]       0  --.-KB/s               \rpreprocessing.py    100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-06 10:42:24 (62.7 MB/s) - ‘preprocessing.py’ saved [3790/3790]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score, classification_report\n",
        "from preprocessing import read_data, load_data, normalize\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "tT2IYaMhYNnG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
        "data_test = pd.read_csv(\"UNSW_NB15_testing-set.csv\")"
      ],
      "metadata": {
        "id": "kABmIs7lU76d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping the 'service' column due to a high number of missing (None) values, making it less useful for analysis.\n"
      ],
      "metadata": {
        "id": "Wr3V-UYa2V1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data_train.drop(columns=\"service\")\n",
        "data_test = data_test.drop(columns=\"service\")"
      ],
      "metadata": {
        "id": "LtuC_B2o1lCm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data_train, data_test], ignore_index=True)"
      ],
      "metadata": {
        "id": "tdgjY63cSxPX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data_train.drop(columns=\"attack_cat\")\n",
        "data_test = data_test.drop(columns=\"attack_cat\")"
      ],
      "metadata": {
        "id": "hqHnT2Poc8Qt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def make_value2index(attacks):\n",
        "    attacks = sorted(attacks)\n",
        "    return {attack: i for i, attack in enumerate(attacks)}\n",
        "\n",
        "# changes label from string to integer/index\n",
        "def encode_label(Y_str):\n",
        "    labels_d = make_value2index(np.unique(Y_str))\n",
        "    Y = np.array([labels_d[attack] for attack in Y_str])\n",
        "    return Y\n",
        "\n",
        "def normalize(data):\n",
        "    data = data.astype(np.float32)\n",
        "    eps = 1e-15\n",
        "    mask = data == -1\n",
        "    data[mask] = 0\n",
        "    mean_i = np.mean(data, axis=0)\n",
        "    min_i = np.min(data, axis=0)\n",
        "    max_i = np.max(data, axis=0)\n",
        "    r = max_i - min_i + eps\n",
        "    data = (data - mean_i) / r\n",
        "    data[mask] = 0\n",
        "    return data\n",
        "\n",
        "def load_data(data):\n",
        "    num_records, num_features = data.shape  # Use shape instead of size()\n",
        "    print(f\"There are {num_records} flow records with {num_features} feature dimensions.\")\n",
        "\n",
        "\n",
        "    # Strip the whitespace from column names\n",
        "    data = data.rename(columns=lambda x: x.strip())\n",
        "    print(\"Stripped column names.\")\n",
        "\n",
        "    # Handle missing values (NaN)\n",
        "    nan_count = data.isnull().sum().sum()\n",
        "    print(f\"There are {nan_count} NaN entries.\")\n",
        "    if nan_count > 0:\n",
        "        data.fillna(data.mean(), inplace=True)\n",
        "        print(\"Filled NaN entries with column mean.\")\n",
        "\n",
        "    # Convert 'proto' and 'state' columns to numeric using Label Encoding, if they exist\n",
        "    if 'proto' in data.columns and 'state' in data.columns:\n",
        "        label_encoder = LabelEncoder()\n",
        "        data['proto'] = label_encoder.fit_transform(data['proto'])\n",
        "        data['state'] = label_encoder.fit_transform(data['state'])\n",
        "        #data['attack_cat'] = label_encoder.fit_transform(data['attack_cat'])\n",
        "        print(\"Converted 'proto' and 'state' columns to numeric using Label Encoding.\")\n",
        "\n",
        "    # Convert all columns to float type\n",
        "    data = data.astype(float)\n",
        "    print(\"Converted all columns to numeric types.\")\n",
        "\n",
        "    # Ensure there are no NaN values\n",
        "    assert data.isnull().sum().sum() == 0, \"There should not be any NaN values.\"\n",
        "    return (data)\n"
      ],
      "metadata": {
        "id": "qPchMR2OXzdK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = load_data(data_train)\n",
        "data_test = load_data(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaXzgEzBYjQo",
        "outputId": "cfff4296-21ae-492d-9f69-a20b09d9431f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 82332 flow records with 43 feature dimensions.\n",
            "Stripped column names.\n",
            "There are 0 NaN entries.\n",
            "Converted 'proto' and 'state' columns to numeric using Label Encoding.\n",
            "Converted all columns to numeric types.\n",
            "There are 175341 flow records with 43 feature dimensions.\n",
            "Stripped column names.\n",
            "There are 0 NaN entries.\n",
            "Converted 'proto' and 'state' columns to numeric using Label Encoding.\n",
            "Converted all columns to numeric types.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data_train.iloc[:, :-1].values\n",
        "X_train = normalize(X_train)\n",
        "y_train = data_train.iloc[:, -1].values\n",
        "X_test = data_test.iloc[:, :-1].values\n",
        "X_test = normalize(X_test)\n",
        "y_test = data_test.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "LQqIITU__AdO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_before, counts_before = np.unique(y_train, return_counts=True)\n",
        "print(\"Class distribution before balancing:\", dict(zip(unique_before, counts_before)))\n",
        "unique_before, counts_before = np.unique(y_test, return_counts=True)\n",
        "print(\"Class distribution before balancing:\", dict(zip(unique_before, counts_before)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9ReC-pEJTjI",
        "outputId": "861b08e8-0a62-4afd-aaac-fa877edf562e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before balancing: {0.0: 37000, 1.0: 45332}\n",
            "Class distribution before balancing: {0.0: 56000, 1.0: 119341}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "of2NAbxMJ_Q-",
        "outputId": "4524e700-7460-4b3a-ca26-c3bf25bf6a00"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esqF4jpFKD1b",
        "outputId": "3874b96b-cb27-4089-9609-4d70bd51af3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6815405410029599\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.84      0.63     56000\n",
            "         1.0       0.89      0.61      0.72    119341\n",
            "\n",
            "    accuracy                           0.68    175341\n",
            "   macro avg       0.70      0.72      0.67    175341\n",
            "weighted avg       0.77      0.68      0.69    175341\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "# Get predicted probabilities\n",
        "y_prob = clf.predict_proba(X_test)[:, 1]  # Taking the probabilities for the positive class (usually index 1)\n",
        "\n",
        "# Calculate Brier Score\n",
        "brier_score = brier_score_loss(y_test, y_prob)\n",
        "print(f\"Brier Score: {brier_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjxTVXOgKGT1",
        "outputId": "e9a176af-7feb-452c-fb05-8cf4ca59043c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brier Score: 0.23450784578755282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "# ROC AUC\n",
        "y_pred_proba = clf.predict_proba(X_test)[:, 1]  # Probability estimates of the positive class\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f'ROC AUC: {roc_auc}')\n",
        "\n",
        "# PR AUC\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f'PR AUC: {pr_auc}')"
      ],
      "metadata": {
        "id": "h3o5bEGbKRP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5658286d-ce0f-4606-d0b2-b02ce5482972"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC: 0.6673924480510232\n",
            "PR AUC: 0.845144408886913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OxjFdBeBlRHS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}